{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "042ed475",
   "metadata": {},
   "source": [
    "# Hackathon Starter Guide\n",
    "\n",
    "This notebook serves as a launchpad and guide to start a first order algorithmic trading strategy. The developer is not limited to but encouraged to use this framework as a basis to get accustomed to the various components involved in a trading strategy.\n",
    "\n",
    "In order to develop an algorithmic trading strategy the following high-level components need to be considered:\n",
    "\n",
    " - *Data* -  Acquire data on the financial assest under test\n",
    " - *Strategy*  - Develop a profitable strategy \n",
    " - *Backtesting* - Backtest your strategy using a framework such as BackTrader, Backtesting.py \n",
    " - *Performance Metrics* - Validate feasibility of strategy against metrics such as CAGR, Drawdown, etc\n",
    "\n",
    "\n",
    "As reference we will follow a [simple example](https://kernc.github.io/backtesting.py/doc/examples/Quick%20Start%20User%20Guide.html) using Backtesting.py\n",
    "\n",
    "\n",
    "Make sure you have installed the `backtesting.py` package (Preferably in a clean Python 3.9 virtual environment) by running the following:\n",
    "\n",
    "`pip install backtesting`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "285c7265",
   "metadata": {},
   "source": [
    "## Data\n",
    "Let's get data some data for our strategy. Backtesting.py has some internal data we can use to test.\n",
    "\n",
    "You can bring your own data on various financial instruments (stocks, forex, crypto, etc) as a pandas.DataFrame with columns `Open`, `High`, `Low`, `Close` and (optionally) `Volume`. The DataFrame should ideally be indexed with a datetime index (convert it with `pd.to_datetime()`).\n",
    "\n",
    "For a more significant test you can download and use Forex data provided by the Spatialedge team. Reach out to one of the mentors. Also see helper function at bottom of notebook to read in parquet data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38763f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-25</th>\n",
       "      <td>802.3</td>\n",
       "      <td>808.41</td>\n",
       "      <td>790.49</td>\n",
       "      <td>790.77</td>\n",
       "      <td>2303900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-26</th>\n",
       "      <td>795.0</td>\n",
       "      <td>795.95</td>\n",
       "      <td>784.40</td>\n",
       "      <td>790.13</td>\n",
       "      <td>2202500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-27</th>\n",
       "      <td>794.8</td>\n",
       "      <td>804.75</td>\n",
       "      <td>791.11</td>\n",
       "      <td>799.78</td>\n",
       "      <td>2026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-28</th>\n",
       "      <td>801.1</td>\n",
       "      <td>806.99</td>\n",
       "      <td>801.03</td>\n",
       "      <td>801.20</td>\n",
       "      <td>2265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-01</th>\n",
       "      <td>797.8</td>\n",
       "      <td>807.14</td>\n",
       "      <td>796.15</td>\n",
       "      <td>806.19</td>\n",
       "      <td>2175400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open    High     Low   Close   Volume\n",
       "2013-02-25  802.3  808.41  790.49  790.77  2303900\n",
       "2013-02-26  795.0  795.95  784.40  790.13  2202500\n",
       "2013-02-27  794.8  804.75  791.11  799.78  2026100\n",
       "2013-02-28  801.1  806.99  801.03  801.20  2265800\n",
       "2013-03-01  797.8  807.14  796.15  806.19  2175400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example OHLC daily data for Google Inc.\n",
    "from backtesting.test import GOOG\n",
    "\n",
    "GOOG.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a987e24e",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "We can now devise a basic strategy by using a simple moving average cross-over."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbf4f0c6",
   "metadata": {},
   "source": [
    "A new strategy needs to extend  Strategy class and override its two abstract methods: `init()` and `next()`.\n",
    "\n",
    " - Method `init()` is invoked before the strategy is run. Within it, one ideally precomputes in efficient, vectorized manner whatever indicators and signals the strategy depends on.\n",
    "\n",
    "- Method `next()` is then iteratively called by the Backtest instance, once for each data point (data frame row), simulating the incremental availability of each new full candlestick bar.\n",
    "\n",
    "Note, backtesting.py cannot make decisions / trades within candlesticks â€” any new orders are executed on the next candle's open (or the current candle's close if `trade_on_close=True`). If you find yourself wishing to trade within candlesticks (e.g. daytrading), you instead need to begin with more fine-grained (e.g. hourly) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75996c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def SMA(values, n):\n",
    "    \"\"\"\n",
    "    Return simple moving average of `values`, at\n",
    "    each step taking into account `n` previous values.\n",
    "    \"\"\"\n",
    "    return pd.Series(values).rolling(n).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dbe0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtesting import Strategy\n",
    "from backtesting.lib import crossover\n",
    "\n",
    "\n",
    "class SmaCross(Strategy):\n",
    "    # Define the two MA lags as *class variables*\n",
    "    # for later optimization\n",
    "    n1 = 10\n",
    "    n2 = 20\n",
    "    \n",
    "    def init(self):\n",
    "        # Precompute the two moving averages\n",
    "        self.sma1 = self.I(SMA, self.data.Close, self.n1)\n",
    "        self.sma2 = self.I(SMA, self.data.Close, self.n2)\n",
    "    \n",
    "    def next(self):\n",
    "        # If sma1 crosses above sma2, close any existing\n",
    "        # short trades, and buy the asset\n",
    "        if crossover(self.sma1, self.sma2):\n",
    "            self.position.close()\n",
    "            self.buy()\n",
    "\n",
    "        # Else, if sma1 crosses below sma2, close any existing\n",
    "        # long trades, and sell the asset\n",
    "        elif crossover(self.sma2, self.sma1):\n",
    "            self.position.close()\n",
    "            self.sell()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de195ca2",
   "metadata": {},
   "source": [
    "## Backtesting\n",
    "\n",
    "Let's see how our strategy performs on historical Google data. The Backtest instance is initialized with OHLC data and a strategy class (see API reference for additional options), and we begin with 10,000 units of cash and set broker's commission to realistic 0.2%.\n",
    "\n",
    "`Backtest.run()` method returns a pandas Series of simulation results and statistics associated with our strategy. We see that this simple strategy makes almost 600% return in the period of 9 years, with maximum drawdown 33%, and with longest drawdown period spanning almost two years ...\n",
    "\n",
    "`Backtest.plot()` method provides the same insights in a more visual form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0efaea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start                     2004-08-19 00:00:00\n",
       "End                       2013-03-01 00:00:00\n",
       "Duration                   3116 days 00:00:00\n",
       "Exposure Time [%]                   97.067039\n",
       "Equity Final [$]                  68221.96986\n",
       "Equity Peak [$]                   68991.21986\n",
       "Return [%]                         582.219699\n",
       "Buy & Hold Return [%]              703.458242\n",
       "Return (Ann.) [%]                   25.266427\n",
       "Volatility (Ann.) [%]               38.383008\n",
       "Sharpe Ratio                         0.658271\n",
       "Sortino Ratio                        1.288779\n",
       "Calmar Ratio                         0.763748\n",
       "Max. Drawdown [%]                  -33.082172\n",
       "Avg. Drawdown [%]                   -5.581506\n",
       "Max. Drawdown Duration      688 days 00:00:00\n",
       "Avg. Drawdown Duration       41 days 00:00:00\n",
       "# Trades                                   94\n",
       "Win Rate [%]                        54.255319\n",
       "Best Trade [%]                       57.11931\n",
       "Worst Trade [%]                    -16.629898\n",
       "Avg. Trade [%]                       2.074326\n",
       "Max. Trade Duration         121 days 00:00:00\n",
       "Avg. Trade Duration          33 days 00:00:00\n",
       "Profit Factor                        2.190805\n",
       "Expectancy [%]                       2.606294\n",
       "SQN                                  1.990216\n",
       "_strategy                            SmaCross\n",
       "_equity_curve                             ...\n",
       "_trades                       Size  EntryB...\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from backtesting import Backtest\n",
    "\n",
    "bt = Backtest(GOOG, SmaCross, cash=10_000, commission=.002)\n",
    "stats = bt.run()\n",
    "stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76f6cc82",
   "metadata": {},
   "source": [
    "Next we will plot our backtest results.\n",
    "\n",
    "Note if you experience the following error: `TypeError: bokeh.models.tools.Toolbar() got multiple values for keyword argument 'logo'`\n",
    "\n",
    "Downgrade `bokeh` by running `pip install bokeh==3.2.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696d1680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/home/bkadmin/.local/lib/python3.11/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%d %b'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n",
      "BokehDeprecationWarning: Passing lists of formats for DatetimeTickFormatter scales was deprecated in Bokeh 3.0. Configure a single string format for each scale\n",
      "/home/bkadmin/.local/lib/python3.11/site-packages/backtesting/_plotting.py:250: UserWarning: DatetimeFormatter scales now only accept a single format. Using the first provided: '%m/%Y'\n",
      "  formatter=DatetimeTickFormatter(days=['%d %b', '%a %d'],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"display: table;\"><div style=\"display: table-row;\"><div style=\"display: table-cell;\"><b title=\"bokeh.models.plots.GridPlot\">GridPlot</b>(</div><div style=\"display: table-cell;\">id&nbsp;=&nbsp;'p1650', <span id=\"p1682\" style=\"cursor: pointer;\">&hellip;)</span></div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">align&nbsp;=&nbsp;'auto',</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">aspect_ratio&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">children&nbsp;=&nbsp;[(figure(id='p1383', ...), 0, 0), (figure(id='p1476', ...), 1, 0), (figure(id='p1343', ...), 2, 0), (figure(id='p1527', ...), 3, 0)],</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">cols&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">context_menu&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">css_classes&nbsp;=&nbsp;[],</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">disabled&nbsp;=&nbsp;False,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">flow_mode&nbsp;=&nbsp;'block',</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">height_policy&nbsp;=&nbsp;'auto',</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_event_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">js_property_callbacks&nbsp;=&nbsp;{},</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">margin&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_height&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">max_width&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_height&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">min_width&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">name&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">resizable&nbsp;=&nbsp;False,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">rows&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">sizing_mode&nbsp;=&nbsp;'stretch_width',</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">spacing&nbsp;=&nbsp;0,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">styles&nbsp;=&nbsp;{},</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">stylesheets&nbsp;=&nbsp;[],</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">subscribed_events&nbsp;=&nbsp;PropertyValueSet(),</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">syncable&nbsp;=&nbsp;True,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">tags&nbsp;=&nbsp;[],</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar&nbsp;=&nbsp;Toolbar(id='p1649', ...),</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">toolbar_location&nbsp;=&nbsp;'right',</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">visible&nbsp;=&nbsp;True,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width&nbsp;=&nbsp;None,</div></div><div class=\"p1681\" style=\"display: none;\"><div style=\"display: table-cell;\"></div><div style=\"display: table-cell;\">width_policy&nbsp;=&nbsp;'auto')</div></div></div>\n",
       "<script>\n",
       "(function() {\n",
       "  let expanded = false;\n",
       "  const ellipsis = document.getElementById(\"p1682\");\n",
       "  ellipsis.addEventListener(\"click\", function() {\n",
       "    const rows = document.getElementsByClassName(\"p1681\");\n",
       "    for (let i = 0; i < rows.length; i++) {\n",
       "      const el = rows[i];\n",
       "      el.style.display = expanded ? \"none\" : \"table-row\";\n",
       "    }\n",
       "    ellipsis.innerHTML = expanded ? \"&hellip;)\" : \"&lsaquo;&lsaquo;&lsaquo;\";\n",
       "    expanded = !expanded;\n",
       "  });\n",
       "})();\n",
       "</script>\n"
      ],
      "text/plain": [
       "GridPlot(id='p1650', ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d45d31bd",
   "metadata": {},
   "source": [
    "## ML strategy\n",
    "\n",
    "For a more sophisticated strategy leveraging Machine Learning, follow [this](https://kernc.github.io/backtesting.py/doc/examples/Trading%20with%20Machine%20Learning.html) tutorial.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54438a0f",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "You can find supplimentary forex data from the following link: <TBC>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a84815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "/path/to/local/data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bkadmin/Github/hackathonn23/Provided files/Welcome_to_Colaboratory.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m SYMBOL \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEURUSD\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m TIMEFRAME \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mH1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m df \u001b[39m=\u001b[39m read_and_process_parquet(DATA_PATH, FROM_DATE, TO_DATE, SYMBOL, TIMEFRAME)\n",
      "\u001b[1;32m/home/bkadmin/Github/hackathonn23/Provided files/Welcome_to_Colaboratory.ipynb Cell 14\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m operator \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m>=\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m<=\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m params \u001b[39m=\u001b[39m [symbol, timeframe, from_date, to_date]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dataset \u001b[39m=\u001b[39m pq\u001b[39m.\u001b[39;49mParquetDataset(data_path, filters\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mzip\u001b[39;49m(partition, operator, params)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m table \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mread()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bkadmin/Github/hackathonn23/Provided%20files/Welcome_to_Colaboratory.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m df \u001b[39m=\u001b[39m table\u001b[39m.\u001b[39mto_pandas()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyarrow/parquet/core.py:1792\u001b[0m, in \u001b[0;36mParquetDataset.__new__\u001b[0;34m(cls, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads, read_dictionary, memory_map, buffer_size, partitioning, use_legacy_dataset, pre_buffer, coerce_int96_timestamp_unit, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         use_legacy_dataset \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_legacy_dataset:\n\u001b[0;32m-> 1792\u001b[0m     \u001b[39mreturn\u001b[39;00m _ParquetDatasetV2(\n\u001b[1;32m   1793\u001b[0m         path_or_paths, filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m   1794\u001b[0m         filters\u001b[39m=\u001b[39;49mfilters,\n\u001b[1;32m   1795\u001b[0m         partitioning\u001b[39m=\u001b[39;49mpartitioning,\n\u001b[1;32m   1796\u001b[0m         read_dictionary\u001b[39m=\u001b[39;49mread_dictionary,\n\u001b[1;32m   1797\u001b[0m         memory_map\u001b[39m=\u001b[39;49mmemory_map,\n\u001b[1;32m   1798\u001b[0m         buffer_size\u001b[39m=\u001b[39;49mbuffer_size,\n\u001b[1;32m   1799\u001b[0m         pre_buffer\u001b[39m=\u001b[39;49mpre_buffer,\n\u001b[1;32m   1800\u001b[0m         coerce_int96_timestamp_unit\u001b[39m=\u001b[39;49mcoerce_int96_timestamp_unit,\n\u001b[1;32m   1801\u001b[0m         \u001b[39m# unsupported keywords\u001b[39;49;00m\n\u001b[1;32m   1802\u001b[0m         schema\u001b[39m=\u001b[39;49mschema, metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m   1803\u001b[0m         split_row_groups\u001b[39m=\u001b[39;49msplit_row_groups,\n\u001b[1;32m   1804\u001b[0m         validate_schema\u001b[39m=\u001b[39;49mvalidate_schema,\n\u001b[1;32m   1805\u001b[0m         metadata_nthreads\u001b[39m=\u001b[39;49mmetadata_nthreads,\n\u001b[1;32m   1806\u001b[0m         thrift_string_size_limit\u001b[39m=\u001b[39;49mthrift_string_size_limit,\n\u001b[1;32m   1807\u001b[0m         thrift_container_size_limit\u001b[39m=\u001b[39;49mthrift_container_size_limit,\n\u001b[1;32m   1808\u001b[0m     )\n\u001b[1;32m   1809\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1810\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPassing \u001b[39m\u001b[39m'\u001b[39m\u001b[39muse_legacy_dataset=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to get the legacy behaviour is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1811\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdeprecated as of pyarrow 11.0.0, and the legacy implementation \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1812\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m extra_msg,\n\u001b[1;32m   1813\u001b[0m     \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   1814\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyarrow/parquet/core.py:2506\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[39mif\u001b[39;00m partitioning \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhive\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2503\u001b[0m     partitioning \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39mHivePartitioning\u001b[39m.\u001b[39mdiscover(\n\u001b[1;32m   2504\u001b[0m         infer_dictionary\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 2506\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset \u001b[39m=\u001b[39m ds\u001b[39m.\u001b[39;49mdataset(path_or_paths, filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m   2507\u001b[0m                            schema\u001b[39m=\u001b[39;49mschema, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mparquet_format,\n\u001b[1;32m   2508\u001b[0m                            partitioning\u001b[39m=\u001b[39;49mpartitioning,\n\u001b[1;32m   2509\u001b[0m                            ignore_prefixes\u001b[39m=\u001b[39;49mignore_prefixes)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyarrow/dataset.py:773\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    762\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    763\u001b[0m     schema\u001b[39m=\u001b[39mschema,\n\u001b[1;32m    764\u001b[0m     filesystem\u001b[39m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    769\u001b[0m     selector_ignore_prefixes\u001b[39m=\u001b[39mignore_prefixes\n\u001b[1;32m    770\u001b[0m )\n\u001b[1;32m    772\u001b[0m \u001b[39mif\u001b[39;00m _is_path_like(source):\n\u001b[0;32m--> 773\u001b[0m     \u001b[39mreturn\u001b[39;00m _filesystem_dataset(source, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    774\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(source, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m    775\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(_is_path_like(elem) \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m source):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyarrow/dataset.py:456\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    454\u001b[0m     fs, paths_or_selector \u001b[39m=\u001b[39m _ensure_multiple_sources(source, filesystem)\n\u001b[1;32m    455\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m     fs, paths_or_selector \u001b[39m=\u001b[39m _ensure_single_source(source, filesystem)\n\u001b[1;32m    458\u001b[0m options \u001b[39m=\u001b[39m FileSystemFactoryOptions(\n\u001b[1;32m    459\u001b[0m     partitioning\u001b[39m=\u001b[39mpartitioning,\n\u001b[1;32m    460\u001b[0m     partition_base_dir\u001b[39m=\u001b[39mpartition_base_dir,\n\u001b[1;32m    461\u001b[0m     exclude_invalid_files\u001b[39m=\u001b[39mexclude_invalid_files,\n\u001b[1;32m    462\u001b[0m     selector_ignore_prefixes\u001b[39m=\u001b[39mselector_ignore_prefixes\n\u001b[1;32m    463\u001b[0m )\n\u001b[1;32m    464\u001b[0m factory \u001b[39m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[39mformat\u001b[39m, options)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pyarrow/dataset.py:432\u001b[0m, in \u001b[0;36m_ensure_single_source\u001b[0;34m(path, filesystem)\u001b[0m\n\u001b[1;32m    430\u001b[0m     paths_or_selector \u001b[39m=\u001b[39m [path]\n\u001b[1;32m    431\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(path)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m filesystem, paths_or_selector\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /path/to/local/data"
     ]
    }
   ],
   "source": [
    "# Helper function to read parquet data into dataframe\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def read_and_process_parquet(data_path, from_date, to_date, symbol, timeframe):\n",
    "    partition = ['symbol','timeframe', 'date', 'date']\n",
    "    operator = ['=', '=', '>=', '<=']\n",
    "    params = [symbol, timeframe, from_date, to_date]\n",
    "            \n",
    "    dataset = pq.ParquetDataset(data_path, filters=list(zip(partition, operator, params)))\n",
    "    table = dataset.read()\n",
    "    df = table.to_pandas()\n",
    "\n",
    "    df['date'] = df['date'].astype(str)\n",
    "    df['time'] = df['time'].astype(str)\n",
    "\n",
    "    df['datetime'] = df['date'] + ' ' + df['time']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y%m%d %H:%M:%S')\n",
    "    df.set_index('datetime', inplace=True)\n",
    "\n",
    "    df.drop(['time', 'symbol', 'timeframe', 'date'], axis=1, inplace=True)\n",
    "    df = df.sort_values('datetime')\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "DATA_PATH='/path/to/local/data/' \n",
    "FROM_DATE='20200101'\n",
    "TO_DATE='20221231'\n",
    "SYMBOL = 'EURUSD'\n",
    "TIMEFRAME = 'H1'\n",
    "\n",
    "df = read_and_process_parquet(DATA_PATH, FROM_DATE, TO_DATE, SYMBOL, TIMEFRAME)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96145a7ed1449a39777181c2aea30e72d82b11b4fab4caaa97a5c2051237b901"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
